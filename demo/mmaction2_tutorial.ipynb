{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VcjSRFELVbNk"
   },
   "source": [
    "# MMAction2 Tutorial\n",
    "\n",
    "Welcome to MMAction2! This is the official colab tutorial for using MMAction2. In this tutorial, you will learn\n",
    "- Perform inference with a MMAction2 recognizer.\n",
    "- Train a new recognizer with a new dataset.\n",
    "\n",
    "\n",
    "Let's start!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LqHGkGEVqpm"
   },
   "source": [
    "## Install MMAction2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bf8PpPXtVvmg",
    "outputId": "9d3f4594-f151-4ee9-a19b-09f8a439ac04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Mon_Apr__3_17:16:06_PDT_2023\n",
      "Cuda compilation tools, release 12.1, V12.1.105\n",
      "Build cuda_12.1.r12.1/compiler.32688072_0\n",
      "gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check nvcc version\n",
    "!nvcc -V\n",
    "# Check GCC version\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZPwKGzqydnb2",
    "outputId": "27506fa7-48a2-4fe0-d377-56f940dafec4"
   },
   "outputs": [],
   "source": [
    "# # install dependencies: (if your colab has CUDA 11.8)\n",
    "# %pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5PAJ4ArzV5Ry",
    "outputId": "eb8539a0-9524-4c48-f3e1-0b013ce0d344"
   },
   "outputs": [],
   "source": [
    "# # install MMEngine, MMCV and MMDetection using MIM\n",
    "# %pip install -U openmim\n",
    "# !mim install mmengine\n",
    "# !mim install \"mmcv>=2.0.0\"\n",
    "\n",
    "# # Install mmaction2\n",
    "# !rm -rf mmaction2\n",
    "# !git clone https://github.com/open-mmlab/mmaction2.git -b main\n",
    "# %cd mmaction2\n",
    "\n",
    "# !pip install -e .\n",
    "\n",
    "# # Install some optional requirements\n",
    "# !pip install -r requirements/optional.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "No_zZAFpWC-a",
    "outputId": "9386dd81-2308-4adb-d3cb-798de11c035e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1 True\n",
      "1.2.0\n",
      "12.1\n",
      "GCC 11.4\n",
      "OrderedDict([('sys.platform', 'linux'), ('Python', '3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]'), ('CUDA available', True), ('MUSA available', False), ('numpy_random_seed', 2147483648), ('GPU 0', 'NVIDIA H100 80GB HBM3'), ('CUDA_HOME', '/usr/local/cuda'), ('NVCC', 'Cuda compilation tools, release 12.1, V12.1.105'), ('GCC', 'gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0'), ('PyTorch', '2.3.1'), ('PyTorch compiling details', 'PyTorch built with:\\n  - GCC 9.3\\n  - C++ Version: 201703\\n  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\\n  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)\\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\\n  - LAPACK is enabled (usually provided by MKL)\\n  - NNPACK is enabled\\n  - CPU capability usage: AVX512\\n  - CUDA Runtime 12.1\\n  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\\n  - CuDNN 8.9.2\\n  - Magma 2.6.1\\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \\n'), ('TorchVision', '0.18.1'), ('OpenCV', '4.10.0'), ('MMEngine', '0.10.4')])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMAction2 installation\n",
    "import mmaction\n",
    "print(mmaction.__version__)\n",
    "\n",
    "# Check MMCV installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())\n",
    "\n",
    "# Check MMEngine installation\n",
    "from mmengine.utils.dl_utils import collect_env\n",
    "print(collect_env())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXf7oV5DWdab"
   },
   "source": [
    "## Perform inference with a MMAction2 recognizer\n",
    "MMAction2 already provides high level APIs to do inference and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "64CW6d_AaT-Q",
    "outputId": "ea330d8c-2e20-4dbd-d046-51d7c9ec4f7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-21 00:39:41--  https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_1x1x3_100e_kinetics400_rgb/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 47.246.29.242, 47.246.29.251, 47.246.29.240, ...\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|47.246.29.242|:443... connected.\n",
      "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
      "\n",
      "    The file is already fully retrieved; nothing to do.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !mkdir /workspace/checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_1x1x3_100e_kinetics400_rgb/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth \\\n",
    "      -O /workspace/checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNZB7NoSabzj",
    "outputId": "c0c2ba71-72ff-4cac-a5b8-65590f5a6bb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /workspace/checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis import inference_recognizer, init_recognizer\n",
    "from mmengine import Config\n",
    "\n",
    "\n",
    "# Choose to use a config and initialize the recognizer\n",
    "config = '/workspace/configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py'\n",
    "config = Config.fromfile(config)\n",
    "# Setup a checkpoint file to load\n",
    "checkpoint = '/workspace/checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
    "# Initialize the recognizer\n",
    "model = init_recognizer(config, checkpoint, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEMsBnpHapAn",
    "outputId": "ec05049e-7289-4798-94fa-2b773cb23634"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/21 00:39:44 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "07/21 00:39:44 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n"
     ]
    }
   ],
   "source": [
    "# Use the recognizer to do inference\n",
    "from operator import itemgetter\n",
    "video = '/workspace/demo/demo.mp4'\n",
    "label = '/workspace/tools/data/kinetics/label_map_k400.txt'\n",
    "results = inference_recognizer(model, video)\n",
    "\n",
    "pred_scores = results.pred_score.tolist()\n",
    "score_tuples = tuple(zip(range(len(pred_scores)), pred_scores))\n",
    "score_sorted = sorted(score_tuples, key=itemgetter(1), reverse=True)\n",
    "top5_label = score_sorted[:5]\n",
    "\n",
    "labels = open(label).readlines()\n",
    "labels = [x.strip() for x in labels]\n",
    "results = [(labels[k[0]], k[1]) for k in top5_label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NIyJXqfWathq",
    "outputId": "cb25aca9-e72d-4c54-f295-4c889713cb3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top-5 labels with corresponding scores are:\n",
      "arm wrestling:  1.0\n",
      "rock scissors paper:  6.4348459893892596e-09\n",
      "shaking hands:  2.758454575868541e-09\n",
      "clapping:  1.3451225688854151e-09\n",
      "massaging feet:  5.55184898054506e-10\n"
     ]
    }
   ],
   "source": [
    "print('The top-5 labels with corresponding scores are:')\n",
    "for result in results:\n",
    "    print(f'{result[0]}: ', result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuZG8kZ2fJ5d"
   },
   "source": [
    "## Train a recognizer on customized dataset\n",
    "\n",
    "To train a new recognizer, there are usually three things to do:\n",
    "1. Support a new dataset\n",
    "2. Modify the config\n",
    "3. Train a new recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neEFyxChfgiJ"
   },
   "source": [
    "### Support a new dataset\n",
    "\n",
    "In this tutorial, we gives an example to convert the data into the format of existing datasets. Other methods and more advanced usages can be found in the [doc](/docs/tutorials/new_dataset.md)\n",
    "\n",
    "Firstly, let's download a tiny dataset obtained from [Kinetics-400](https://deepmind.com/research/open-source/open-source-datasets/kinetics/). We select 30 videos with their labels as train dataset and 10 videos with their labels as test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjsUj9JzgUlJ",
    "outputId": "96a0e6e9-0dd8-4c07-9fed-22b93d5c1318"
   },
   "outputs": [],
   "source": [
    "# # download, decompress the data\n",
    "# !rm kinetics400_tiny.zip*\n",
    "# !rm -rf kinetics400_tiny\n",
    "# !wget https://download.openmmlab.com/mmaction/kinetics400_tiny.zip\n",
    "# !unzip kinetics400_tiny.zip > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbZ-o7V6hNw4",
    "outputId": "f229f352-1b43-41b7-a374-21404f618581"
   },
   "outputs": [],
   "source": [
    "# # Check the directory structure of the tiny data\n",
    "\n",
    "# # Install tree first\n",
    "# !apt-get -q install tree\n",
    "# !tree kinetics400_tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fTdi6dI0hY3g",
    "outputId": "95f22438-566c-4496-fe0c-50e128b47b5e"
   },
   "outputs": [],
   "source": [
    "# # After downloading the data, we need to check the annotation format\n",
    "# !cat kinetics400_tiny/kinetics_tiny_train_video.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bq0mxmEi29H"
   },
   "source": [
    "According to the format defined in [`VideoDataset`](./datasets/video_dataset.py), each line indicates a sample video with the filepath and label, which are split with a whitespace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ht_DGJA9jQar"
   },
   "source": [
    "### Modify the config\n",
    "\n",
    "In the next step, we need to modify the config for the training.\n",
    "To accelerate the process, we finetune a recognizer using a pre-trained recognizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LjCcmCKOjktc"
   },
   "outputs": [],
   "source": [
    "cfg = Config.fromfile('/workspace/configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tc8YhFFGjp3e"
   },
   "source": [
    "Given a config that trains a TSN model on kinetics400-full dataset, we need to modify some values to use it for training TSN on Kinetics400-tiny dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tES-qnZ3k38Z"
   },
   "source": [
    "### Train a new recognizer\n",
    "\n",
    "Finally, lets initialize the dataset and recognizer, then train a new recognizer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "ann_file_train = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
      "ann_file_val = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
      "auto_scale_lr = dict(base_batch_size=256, enable=False)\n",
      "data_root = 'kinetics400_tiny/train/'\n",
      "data_root_val = 'kinetics400_tiny/val/'\n",
      "dataset_type = 'VideoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=3, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=20, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "file_client_args = dict(io_backend='disk')\n",
      "load_from = '/workspace/checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=50,\n",
      "        norm_eval=False,\n",
      "        pretrained='https://download.pytorch.org/models/resnet50-11ad3fa6.pth',\n",
      "        type='ResNet'),\n",
      "    cls_head=dict(\n",
      "        average_clips='prob',\n",
      "        consensus=dict(dim=1, type='AvgConsensus'),\n",
      "        dropout_ratio=0.4,\n",
      "        in_channels=2048,\n",
      "        init_std=0.01,\n",
      "        num_classes=2,\n",
      "        spatial_type='avg',\n",
      "        type='TSNHead'),\n",
      "    data_preprocessor=dict(\n",
      "        format_shape='NCHW',\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='ActionDataPreprocessor'),\n",
      "    test_cfg=None,\n",
      "    train_cfg=None,\n",
      "    type='Recognizer2D')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=40, norm_type=2),\n",
      "    optimizer=dict(\n",
      "        lr=7.8125e-05, momentum=0.9, type='SGD', weight_decay=0.0001))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=100,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            40,\n",
      "            80,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
      "        data_prefix=dict(video='kinetics400_tiny/val/'),\n",
      "        pipeline=[\n",
      "            dict(io_backend='disk', type='DecordInit'),\n",
      "            dict(\n",
      "                clip_len=1,\n",
      "                frame_interval=1,\n",
      "                num_clips=25,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='TenCrop'),\n",
      "            dict(input_format='NCHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='VideoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(type='AccMetric')\n",
      "test_pipeline = [\n",
      "    dict(io_backend='disk', type='DecordInit'),\n",
      "    dict(\n",
      "        clip_len=1,\n",
      "        frame_interval=1,\n",
      "        num_clips=25,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='TenCrop'),\n",
      "    dict(input_format='NCHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=10, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='kinetics400_tiny/kinetics_tiny_train_video.txt',\n",
      "        data_prefix=dict(video='kinetics400_tiny/train/'),\n",
      "        pipeline=[\n",
      "            dict(io_backend='disk', type='DecordInit'),\n",
      "            dict(\n",
      "                clip_len=1, frame_interval=1, num_clips=3,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                input_size=224,\n",
      "                max_wh_scale_gap=1,\n",
      "                random_crop=False,\n",
      "                scales=(\n",
      "                    1,\n",
      "                    0.875,\n",
      "                    0.75,\n",
      "                    0.66,\n",
      "                ),\n",
      "                type='MultiScaleCrop'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                224,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(flip_ratio=0.5, type='Flip'),\n",
      "            dict(input_format='NCHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        type='VideoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(io_backend='disk', type='DecordInit'),\n",
      "    dict(clip_len=1, frame_interval=1, num_clips=3, type='SampleFrames'),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        input_size=224,\n",
      "        max_wh_scale_gap=1,\n",
      "        random_crop=False,\n",
      "        scales=(\n",
      "            1,\n",
      "            0.875,\n",
      "            0.75,\n",
      "            0.66,\n",
      "        ),\n",
      "        type='MultiScaleCrop'),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        224,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(flip_ratio=0.5, type='Flip'),\n",
      "    dict(input_format='NCHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
      "        data_prefix=dict(video='kinetics400_tiny/val/'),\n",
      "        pipeline=[\n",
      "            dict(io_backend='disk', type='DecordInit'),\n",
      "            dict(\n",
      "                clip_len=1,\n",
      "                frame_interval=1,\n",
      "                num_clips=3,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(input_format='NCHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='VideoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(type='AccMetric')\n",
      "val_pipeline = [\n",
      "    dict(io_backend='disk', type='DecordInit'),\n",
      "    dict(\n",
      "        clip_len=1,\n",
      "        frame_interval=1,\n",
      "        num_clips=3,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='CenterCrop'),\n",
      "    dict(input_format='NCHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = '/workspace/checkpoints/tutorial_exps'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmengine.runner import set_random_seed\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.data_root = 'kinetics400_tiny/train/'\n",
    "cfg.data_root_val = 'kinetics400_tiny/val/'\n",
    "cfg.ann_file_train = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
    "cfg.ann_file_val = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
    "\n",
    "\n",
    "cfg.test_dataloader.dataset.ann_file = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
    "cfg.test_dataloader.dataset.data_prefix.video = 'kinetics400_tiny/val/'\n",
    "\n",
    "cfg.train_dataloader.dataset.ann_file = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
    "cfg.train_dataloader.dataset.data_prefix.video = 'kinetics400_tiny/train/'\n",
    "\n",
    "cfg.val_dataloader.dataset.ann_file = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
    "cfg.val_dataloader.dataset.data_prefix.video  = 'kinetics400_tiny/val/'\n",
    "\n",
    "\n",
    "# Modify num classes of the model in cls_head\n",
    "cfg.model.cls_head.num_classes = 2\n",
    "# We can use the pre-trained TSN model\n",
    "cfg.load_from = '/workspace/checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = '/workspace/checkpoints/tutorial_exps'\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.train_dataloader.batch_size = cfg.train_dataloader.batch_size // 16\n",
    "cfg.val_dataloader.batch_size = cfg.val_dataloader.batch_size // 16\n",
    "cfg.optim_wrapper.optimizer.lr = cfg.optim_wrapper.optimizer.lr / 8 / 16\n",
    "cfg.train_cfg.max_epochs = 10\n",
    "\n",
    "cfg.train_dataloader.num_workers = 2\n",
    "cfg.val_dataloader.num_workers = 2\n",
    "cfg.test_dataloader.num_workers = 2\n",
    "\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDBWkdDRk6oz",
    "outputId": "044b9e09-2038-41c9-d5a3-8a74ae11ade2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/21 00:39:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "------------------------------------------------------------\n",
      "System environment:\n",
      "    sys.platform: linux\n",
      "    Python: 3.10.14 (main, May  6 2024, 19:42:50) [GCC 11.2.0]\n",
      "    CUDA available: True\n",
      "    MUSA available: False\n",
      "    numpy_random_seed: 460318568\n",
      "    GPU 0: NVIDIA H100 80GB HBM3\n",
      "    CUDA_HOME: /usr/local/cuda\n",
      "    NVCC: Cuda compilation tools, release 12.1, V12.1.105\n",
      "    GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "    PyTorch: 2.3.1\n",
      "    PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX512\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9.2\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.1, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "    TorchVision: 0.18.1\n",
      "    OpenCV: 4.10.0\n",
      "    MMEngine: 0.10.4\n",
      "\n",
      "Runtime environment:\n",
      "    cudnn_benchmark: False\n",
      "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
      "    dist_cfg: {'backend': 'nccl'}\n",
      "    seed: 460318568\n",
      "    Distributed launcher: none\n",
      "    Distributed training: False\n",
      "    GPU number: 1\n",
      "------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/21 00:39:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
      "ann_file_train = 'kinetics400_tiny/kinetics_tiny_train_video.txt'\n",
      "ann_file_val = 'kinetics400_tiny/kinetics_tiny_val_video.txt'\n",
      "auto_scale_lr = dict(base_batch_size=256, enable=False)\n",
      "data_root = 'kinetics400_tiny/train/'\n",
      "data_root_val = 'kinetics400_tiny/val/'\n",
      "dataset_type = 'VideoDataset'\n",
      "default_hooks = dict(\n",
      "    checkpoint=dict(\n",
      "        interval=3, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
      "    logger=dict(ignore_last=False, interval=20, type='LoggerHook'),\n",
      "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
      "    runtime_info=dict(type='RuntimeInfoHook'),\n",
      "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
      "    sync_buffers=dict(type='SyncBuffersHook'),\n",
      "    timer=dict(type='IterTimerHook'))\n",
      "default_scope = 'mmaction'\n",
      "env_cfg = dict(\n",
      "    cudnn_benchmark=False,\n",
      "    dist_cfg=dict(backend='nccl'),\n",
      "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
      "file_client_args = dict(io_backend='disk')\n",
      "load_from = '/workspace/checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth'\n",
      "log_level = 'INFO'\n",
      "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
      "model = dict(\n",
      "    backbone=dict(\n",
      "        depth=50,\n",
      "        norm_eval=False,\n",
      "        pretrained='https://download.pytorch.org/models/resnet50-11ad3fa6.pth',\n",
      "        type='ResNet'),\n",
      "    cls_head=dict(\n",
      "        average_clips='prob',\n",
      "        consensus=dict(dim=1, type='AvgConsensus'),\n",
      "        dropout_ratio=0.4,\n",
      "        in_channels=2048,\n",
      "        init_std=0.01,\n",
      "        num_classes=2,\n",
      "        spatial_type='avg',\n",
      "        type='TSNHead'),\n",
      "    data_preprocessor=dict(\n",
      "        format_shape='NCHW',\n",
      "        mean=[\n",
      "            123.675,\n",
      "            116.28,\n",
      "            103.53,\n",
      "        ],\n",
      "        std=[\n",
      "            58.395,\n",
      "            57.12,\n",
      "            57.375,\n",
      "        ],\n",
      "        type='ActionDataPreprocessor'),\n",
      "    test_cfg=None,\n",
      "    train_cfg=None,\n",
      "    type='Recognizer2D')\n",
      "optim_wrapper = dict(\n",
      "    clip_grad=dict(max_norm=40, norm_type=2),\n",
      "    optimizer=dict(\n",
      "        lr=7.8125e-05, momentum=0.9, type='SGD', weight_decay=0.0001))\n",
      "param_scheduler = [\n",
      "    dict(\n",
      "        begin=0,\n",
      "        by_epoch=True,\n",
      "        end=100,\n",
      "        gamma=0.1,\n",
      "        milestones=[\n",
      "            40,\n",
      "            80,\n",
      "        ],\n",
      "        type='MultiStepLR'),\n",
      "]\n",
      "resume = False\n",
      "test_cfg = dict(type='TestLoop')\n",
      "test_dataloader = dict(\n",
      "    batch_size=1,\n",
      "    dataset=dict(\n",
      "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
      "        data_prefix=dict(video='kinetics400_tiny/val/'),\n",
      "        pipeline=[\n",
      "            dict(io_backend='disk', type='DecordInit'),\n",
      "            dict(\n",
      "                clip_len=1,\n",
      "                frame_interval=1,\n",
      "                num_clips=25,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='TenCrop'),\n",
      "            dict(input_format='NCHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='VideoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "test_evaluator = dict(type='AccMetric')\n",
      "test_pipeline = [\n",
      "    dict(io_backend='disk', type='DecordInit'),\n",
      "    dict(\n",
      "        clip_len=1,\n",
      "        frame_interval=1,\n",
      "        num_clips=25,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='TenCrop'),\n",
      "    dict(input_format='NCHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "train_cfg = dict(\n",
      "    max_epochs=10, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
      "train_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='kinetics400_tiny/kinetics_tiny_train_video.txt',\n",
      "        data_prefix=dict(video='kinetics400_tiny/train/'),\n",
      "        pipeline=[\n",
      "            dict(io_backend='disk', type='DecordInit'),\n",
      "            dict(\n",
      "                clip_len=1, frame_interval=1, num_clips=3,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(\n",
      "                input_size=224,\n",
      "                max_wh_scale_gap=1,\n",
      "                random_crop=False,\n",
      "                scales=(\n",
      "                    1,\n",
      "                    0.875,\n",
      "                    0.75,\n",
      "                    0.66,\n",
      "                ),\n",
      "                type='MultiScaleCrop'),\n",
      "            dict(keep_ratio=False, scale=(\n",
      "                224,\n",
      "                224,\n",
      "            ), type='Resize'),\n",
      "            dict(flip_ratio=0.5, type='Flip'),\n",
      "            dict(input_format='NCHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        type='VideoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
      "train_pipeline = [\n",
      "    dict(io_backend='disk', type='DecordInit'),\n",
      "    dict(clip_len=1, frame_interval=1, num_clips=3, type='SampleFrames'),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(\n",
      "        input_size=224,\n",
      "        max_wh_scale_gap=1,\n",
      "        random_crop=False,\n",
      "        scales=(\n",
      "            1,\n",
      "            0.875,\n",
      "            0.75,\n",
      "            0.66,\n",
      "        ),\n",
      "        type='MultiScaleCrop'),\n",
      "    dict(keep_ratio=False, scale=(\n",
      "        224,\n",
      "        224,\n",
      "    ), type='Resize'),\n",
      "    dict(flip_ratio=0.5, type='Flip'),\n",
      "    dict(input_format='NCHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "val_cfg = dict(type='ValLoop')\n",
      "val_dataloader = dict(\n",
      "    batch_size=2,\n",
      "    dataset=dict(\n",
      "        ann_file='kinetics400_tiny/kinetics_tiny_val_video.txt',\n",
      "        data_prefix=dict(video='kinetics400_tiny/val/'),\n",
      "        pipeline=[\n",
      "            dict(io_backend='disk', type='DecordInit'),\n",
      "            dict(\n",
      "                clip_len=1,\n",
      "                frame_interval=1,\n",
      "                num_clips=3,\n",
      "                test_mode=True,\n",
      "                type='SampleFrames'),\n",
      "            dict(type='DecordDecode'),\n",
      "            dict(scale=(\n",
      "                -1,\n",
      "                256,\n",
      "            ), type='Resize'),\n",
      "            dict(crop_size=224, type='CenterCrop'),\n",
      "            dict(input_format='NCHW', type='FormatShape'),\n",
      "            dict(type='PackActionInputs'),\n",
      "        ],\n",
      "        test_mode=True,\n",
      "        type='VideoDataset'),\n",
      "    num_workers=2,\n",
      "    persistent_workers=True,\n",
      "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
      "val_evaluator = dict(type='AccMetric')\n",
      "val_pipeline = [\n",
      "    dict(io_backend='disk', type='DecordInit'),\n",
      "    dict(\n",
      "        clip_len=1,\n",
      "        frame_interval=1,\n",
      "        num_clips=3,\n",
      "        test_mode=True,\n",
      "        type='SampleFrames'),\n",
      "    dict(type='DecordDecode'),\n",
      "    dict(scale=(\n",
      "        -1,\n",
      "        256,\n",
      "    ), type='Resize'),\n",
      "    dict(crop_size=224, type='CenterCrop'),\n",
      "    dict(input_format='NCHW', type='FormatShape'),\n",
      "    dict(type='PackActionInputs'),\n",
      "]\n",
      "vis_backends = [\n",
      "    dict(type='LocalVisBackend'),\n",
      "]\n",
      "visualizer = dict(\n",
      "    type='ActionVisualizer', vis_backends=[\n",
      "        dict(type='LocalVisBackend'),\n",
      "    ])\n",
      "work_dir = '/workspace/checkpoints/tutorial_exps'\n",
      "\n",
      "07/21 00:39:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
      "07/21 00:39:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "before_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(NORMAL      ) SyncBuffersHook                    \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      "(LOW         ) ParamSchedulerHook                 \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "after_val:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_train:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(VERY_LOW    ) CheckpointHook                     \n",
      " -------------------- \n",
      "before_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "before_test_epoch:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "before_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_test_iter:\n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test_epoch:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      "(NORMAL      ) IterTimerHook                      \n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "after_test:\n",
      "(VERY_HIGH   ) RuntimeInfoHook                    \n",
      " -------------------- \n",
      "after_run:\n",
      "(BELOW_NORMAL) LoggerHook                         \n",
      " -------------------- \n",
      "Loads checkpoint by http backend from path: https://download.pytorch.org/models/resnet50-11ad3fa6.pth\n",
      "07/21 00:39:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - These parameters in pretrained checkpoint are not loaded: {'fc.weight', 'fc.bias'}\n",
      "Loads checkpoint by local backend from path: /workspace/checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 2048]) from checkpoint, the shape in current model is torch.Size([2, 2048]).\n",
      "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "07/21 00:39:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from /workspace/checkpoints/tsn_r50_1x1x3_100e_kinetics400_rgb_20200614-e508be42.pth\n",
      "07/21 00:39:46 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
      "07/21 00:39:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /workspace/checkpoints/tutorial_exps.\n",
      "07/21 00:39:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240721_003944\n",
      "07/21 00:39:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][15/15]  lr: 7.8125e-05  eta: 0:00:18  time: 0.1391  data_time: 0.0693  memory: 2918  grad_norm: 12.7138  loss: 0.6983  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6983\n",
      "07/21 00:39:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][5/5]    acc/top1: 0.7000  acc/top5: 1.0000  acc/mean1: 0.7000  data_time: 0.1543  time: 0.1715\n",
      "07/21 00:39:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7000 acc/top1 at 1 epoch is saved to best_acc_top1_epoch_1.pth.\n",
      "07/21 00:39:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240721_003944\n",
      "07/21 00:39:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][15/15]  lr: 7.8125e-05  eta: 0:00:15  time: 0.1131  data_time: 0.0784  memory: 1000  grad_norm: 11.9391  loss: 0.6620  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6620\n",
      "07/21 00:39:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][5/5]    acc/top1: 0.8000  acc/top5: 1.0000  acc/mean1: 0.8000  data_time: 0.1397  time: 0.1551\n",
      "07/21 00:39:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /workspace/checkpoints/tutorial_exps/best_acc_top1_epoch_1.pth is removed\n",
      "07/21 00:39:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.8000 acc/top1 at 2 epoch is saved to best_acc_top1_epoch_2.pth.\n",
      "07/21 00:39:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240721_003944\n",
      "07/21 00:39:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][15/15]  lr: 7.8125e-05  eta: 0:00:12  time: 0.1013  data_time: 0.0645  memory: 1000  grad_norm: 11.8318  loss: 0.6541  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6541\n",
      "07/21 00:39:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
      "07/21 00:39:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][5/5]    acc/top1: 0.8000  acc/top5: 1.0000  acc/mean1: 0.8000  data_time: 0.1480  time: 0.1635\n",
      "07/21 00:39:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240721_003944\n",
      "07/21 00:39:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][15/15]  lr: 7.8125e-05  eta: 0:00:10  time: 0.1054  data_time: 0.0737  memory: 1000  grad_norm: 12.4906  loss: 0.6773  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.6773\n",
      "07/21 00:39:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][5/5]    acc/top1: 0.7000  acc/top5: 1.0000  acc/mean1: 0.7000  data_time: 0.1414  time: 0.1553\n",
      "07/21 00:40:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240721_003944\n",
      "07/21 00:40:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][15/15]  lr: 7.8125e-05  eta: 0:00:08  time: 0.1095  data_time: 0.0786  memory: 1000  grad_norm: 12.9619  loss: 0.6999  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6999\n",
      "07/21 00:40:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][5/5]    acc/top1: 1.0000  acc/top5: 1.0000  acc/mean1: 1.0000  data_time: 0.1392  time: 0.1511\n",
      "07/21 00:40:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /workspace/checkpoints/tutorial_exps/best_acc_top1_epoch_2.pth is removed\n",
      "07/21 00:40:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 1.0000 acc/top1 at 5 epoch is saved to best_acc_top1_epoch_5.pth.\n",
      "07/21 00:40:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240721_003944\n",
      "07/21 00:40:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][15/15]  lr: 7.8125e-05  eta: 0:00:06  time: 0.1042  data_time: 0.0694  memory: 1000  grad_norm: 10.7158  loss: 0.5960  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.5960\n",
      "07/21 00:40:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n",
      "07/21 00:40:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [6][5/5]    acc/top1: 1.0000  acc/top5: 1.0000  acc/mean1: 1.0000  data_time: 0.1440  time: 0.1579\n",
      "07/21 00:40:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240721_003944\n",
      "07/21 00:40:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][15/15]  lr: 7.8125e-05  eta: 0:00:04  time: 0.1004  data_time: 0.0670  memory: 1000  grad_norm: 11.7742  loss: 0.6249  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6249\n",
      "07/21 00:40:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [7][5/5]    acc/top1: 0.7000  acc/top5: 1.0000  acc/mean1: 0.7000  data_time: 0.1408  time: 0.1514\n",
      "07/21 00:40:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240721_003944\n",
      "07/21 00:40:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][15/15]  lr: 7.8125e-05  eta: 0:00:03  time: 0.0950  data_time: 0.0621  memory: 1000  grad_norm: 12.4235  loss: 0.6430  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6430\n",
      "07/21 00:40:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [8][5/5]    acc/top1: 1.0000  acc/top5: 1.0000  acc/mean1: 1.0000  data_time: 0.1397  time: 0.1514\n",
      "07/21 00:40:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240721_003944\n",
      "07/21 00:40:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][15/15]  lr: 7.8125e-05  eta: 0:00:01  time: 0.1049  data_time: 0.0723  memory: 1000  grad_norm: 12.4780  loss: 0.6276  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6276\n",
      "07/21 00:40:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 9 epochs\n",
      "07/21 00:40:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [9][5/5]    acc/top1: 1.0000  acc/top5: 1.0000  acc/mean1: 1.0000  data_time: 0.1326  time: 0.1516\n",
      "07/21 00:40:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb_20240721_003944\n",
      "07/21 00:40:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][15/15]  lr: 7.8125e-05  eta: 0:00:00  time: 0.1265  data_time: 0.0929  memory: 1000  grad_norm: 11.2670  loss: 0.5651  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5651\n",
      "07/21 00:40:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 10 epochs\n",
      "07/21 00:40:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][5/5]    acc/top1: 1.0000  acc/top5: 1.0000  acc/mean1: 1.0000  data_time: 0.1299  time: 0.1477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Recognizer2D(\n",
       "  (data_preprocessor): ActionDataPreprocessor()\n",
       "  (backbone): ResNet(\n",
       "    (conv1): ConvModule(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activate): ReLU(inplace=True)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): ConvModule(\n",
       "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): ConvModule(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): ConvModule(\n",
       "          (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): ConvModule(\n",
       "          (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): ConvModule(\n",
       "          (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvModule(\n",
       "          (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activate): ReLU(inplace=True)\n",
       "        )\n",
       "        (conv3): ConvModule(\n",
       "          (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  init_cfg=[{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'layer': 'BatchNorm2d', 'val': 1.0}]\n",
       "  (cls_head): TSNHead(\n",
       "    (loss_cls): CrossEntropyLoss()\n",
       "    (consensus): AvgConsensus()\n",
       "    (avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (dropout): Dropout(p=0.4, inplace=False)\n",
       "    (fc_cls): Linear(in_features=2048, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path as osp\n",
    "import mmengine\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "# Create work_dir\n",
    "mmengine.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "\n",
    "# build the runner from config\n",
    "runner = Runner.from_cfg(cfg)\n",
    "\n",
    "# start training\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdSd7oTLlxIf"
   },
   "source": [
    "### Understand the log\n",
    "From the log, we can have a basic understanding the training process and know how well the recognizer is trained.\n",
    "\n",
    "Firstly, the ResNet-50 backbone pre-trained on ImageNet is loaded, this is a common practice since training from scratch is more cost. The log shows that all the weights of the ResNet-50 backbone are loaded except the `fc.bias` and `fc.weight`.\n",
    "\n",
    "Second, since the dataset we are using is small, we loaded a TSN model and finetune it for action recognition.\n",
    "The original TSN is trained on original Kinetics-400 dataset which contains 400 classes but Kinetics-400 Tiny dataset only have 2 classes. Therefore, the last FC layer of the pre-trained TSN for classification has different weight shape and is not used.\n",
    "\n",
    "Third, after training, the recognizer is evaluated by the default evaluation. The results show that the recognizer achieves 100% top1 accuracy and 100% top5 accuracy on the val dataset,\n",
    " \n",
    "Not bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryVoSfZVmogw"
   },
   "source": [
    "## Test the trained recognizer\n",
    "\n",
    "After finetuning the recognizer, let's check the prediction results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyY3hCMwyTct",
    "outputId": "34fbbdc5-b9fd-4fd2-8030-3ba56b10adbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07/21 00:40:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(test) [10/10]    acc/top1: 1.0000  acc/top5: 1.0000  acc/mean1: 1.0000  data_time: 0.1336  time: 0.1909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc/top1': 1.0, 'acc/top5': 1.0, 'acc/mean1': 1.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mmact_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "189c342a4747645665e89db23000ac4d4edb7a87c4cd0b2f881610f468fb778d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
